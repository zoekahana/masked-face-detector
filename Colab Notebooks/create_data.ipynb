{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"create_data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNhornAqvsMb0hRnKEIjQRr"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"nuhxUNxv4TKJ","executionInfo":{"status":"ok","timestamp":1607393315381,"user_tz":360,"elapsed":413,"user":{"displayName":"Zoe Kahana","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUYqN7RUzNvu9326orruFNPolStScBKAFwNcx5HA=s64","userId":"04301351105095480529"}}},"source":["import json\n","import os\n","import torch\n","import random\n","import xml.etree.ElementTree as ET\n","import torchvision.transforms.functional as FT\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Label map\n","voc_labels = ('with_mask', 'without_mask')\n","label_map = {k: v + 1 for v, k in enumerate(voc_labels)}\n","label_map['background'] = 0\n","rev_label_map = {v: k for k, v in label_map.items()}  # Inverse mapping\n","\n","# Color map for bounding boxes of detected objects from https://sashat.me/2017/01/11/list-of-20-simple-distinct-colors/\n","distinct_colors = ['#e6194b', '#3cb44b', '#ffe119']\n","label_color_map = {k: distinct_colors[i] for i, k in enumerate(label_map.keys())}\n","\n","\n","def parse_annotation(annotation_path):\n","    tree = ET.parse(annotation_path)\n","    root = tree.getroot()\n","\n","    boxes = list()\n","    labels = list()\n","    difficulties = list()\n","    for object in root.iter('object'):\n","\n","        difficult = int(object.find('difficult').text == '1')\n","\n","        label = object.find('name').text.lower().strip()\n","        if label not in label_map:\n","            continue\n","\n","        bbox = object.find('bndbox')\n","        xmin = int(bbox.find('xmin').text) - 1\n","        ymin = int(bbox.find('ymin').text) - 1\n","        xmax = int(bbox.find('xmax').text) - 1\n","        ymax = int(bbox.find('ymax').text) - 1\n","\n","        boxes.append([xmin, ymin, xmax, ymax])\n","        labels.append(label_map[label])\n","        difficulties.append(difficult)\n","\n","    return {'boxes': boxes, 'labels': labels, 'difficulties': difficulties}\n","\n","\n","def create_data_lists(train_path, test_path, val_path, output_folder):\n","    \"\"\"\n","    Create lists of images, the bounding boxes and labels of the objects in these images, and save these to file.\n","\n","    :param train_path: path to training images and annotations\n","    :param test_path: path to test images and annotations\n","    :param val_path: path to validation images and annotations\n","    :param output_folder: folder where the JSONs must be saved\n","    \"\"\"\n","    \n","    \n","    train_path = os.path.abspath(train_path)\n","    print(\"TRAIN PATH:\", train_path)\n","\n","    train_images = list()\n","    train_objects = list()\n","    n_objects = 0\n","\n","    # Training data\n","    for path in os.listdir(train_path):\n","\n","        if path == '.DS_Store':\n","            continue\n","        \n","        path = os.path.join(train_path, path)\n","        print(\"PATH:\", path)\n","        \n","        ann_path = os.path.join(path, 'annotations')\n","        img_path = os.path.join(path, 'images')\n","\n","        for xml in os.listdir(ann_path):\n","            if xml == '.DS_Store':\n","                continue\n","            print(xml)\n","            name = xml[0 : xml.index('.')]\n","            # Parse annotation's XML file\n","            objects = parse_annotation(os.path.join(ann_path, xml))\n","            if len(objects['boxes']) == 0:\n","                continue\n","            n_objects += len(objects)\n","            train_objects.append(objects)\n","            train_images.append(os.path.join(img_path, name + '.jpg'))\n","\n","    assert len(train_objects) == len(train_images)\n","\n","    # Save to file\n","    with open(os.path.join(output_folder, 'TRAIN_images.json'), 'w') as j:\n","        json.dump(train_images, j)\n","    with open(os.path.join(output_folder, 'TRAIN_objects.json'), 'w') as j:\n","        json.dump(train_objects, j)\n","    with open(os.path.join(output_folder, 'label_map.json'), 'w') as j:\n","        json.dump(label_map, j)  # save label map too\n","\n","    print('\\nThere are %d training images containing a total of %d objects. Files have been saved to %s.' % (\n","        len(train_images), n_objects, os.path.abspath(output_folder)))\n","    \n","    # Test data\n","    test_images = list()\n","    test_objects = list()\n","    n_objects = 0\n","    print(\"TEST PATH:\", test_path)\n","    \n","    for path in os.listdir(test_path):\n","\n","        if path == '.DS_Store':\n","            continue\n","        \n","        path = os.path.join(test_path, path)\n","        print(\"PATH:\", path)\n","        \n","        ann_path = os.path.join(path, 'annotations')\n","        img_path = os.path.join(path, 'images')\n","\n","        for xml in os.listdir(ann_path):\n","            if xml == '.DS_Store':\n","                continue\n","            name = xml[0 : xml.index('.')]\n","            print(xml)\n","            # Parse annotation's XML file\n","            objects = parse_annotation(os.path.join(ann_path, xml))\n","            if len(objects['boxes']) == 0:\n","                continue\n","            n_objects += len(objects)\n","            test_objects.append(objects)\n","            test_images.append(os.path.join(img_path, name + '.jpg'))\n","\n","    assert len(test_objects) == len(test_images)\n","\n","    # Save to file\n","    with open(os.path.join(output_folder, 'CROWDS_images.json'), 'w') as j:\n","        json.dump(test_images, j)\n","    with open(os.path.join(output_folder, 'CROWDS_objects.json'), 'w') as j:\n","        json.dump(test_objects, j)\n","\n","    print('\\nThere are %d test images containing a total of %d objects. Files have been saved to %s.' % (\n","        len(test_images), n_objects, os.path.abspath(output_folder)))\n","\n","   # Validation data\n","    val_images = list()\n","    val_objects = list()\n","    n_objects = 0\n","    print(\"VAL PATH:\", val_path)\n","\n","    for path in os.listdir(val_path):\n","\n","        if path == '.DS_Store':\n","            continue\n","        \n","        path = os.path.join(val_path, path)\n","        print(\"PATH:\", path)\n","        \n","        ann_path = os.path.join(path, 'annotations')\n","        img_path = os.path.join(path, 'images')\n","\n","        for xml in os.listdir(ann_path):\n","            if xml == '.DS_Store':\n","                continue\n","            name = xml[0 : xml.index('.')]\n","            print(xml)\n","            # Parse annotation's XML file\n","            objects = parse_annotation(os.path.join(ann_path, xml))\n","            if len(objects['boxes']) == 0:\n","                continue\n","            n_objects += len(objects)\n","            val_objects.append(objects)\n","            val_images.append(os.path.join(img_path, name + '.jpg'))\n","\n","    assert len(val_objects) == len(val_images)\n","\n","    # Save to file\n","    with open(os.path.join(output_folder, 'VAL_images.json'), 'w') as j:\n","        json.dump(val_images, j)\n","    with open(os.path.join(output_folder, 'VAL_objects.json'), 'w') as j:\n","        json.dump(val_objects, j)\n","\n","    print('\\nThere are %d validation images containing a total of %d objects. Files have been saved to %s.' % (\n","        len(val_images), n_objects, os.path.abspath(output_folder)))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"TeRTLOaw4ipI"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","create_data_lists(train_path='/content/drive/My Drive/masked-face-detector/data/train',\n","                      test_path='/content/drive/My Drive/masked-face-detector/data/test',\n","                      val_path='/content/drive/My Drive/masked-face-detector/data/validation',\n","                      output_folder='/content/drive/My Drive/masked-face-detector/output')"],"execution_count":null,"outputs":[]}]}